{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### jefan \n",
    "#### begun: Dec 29 2016, updated: Jul 15 2018\n",
    "#### analysis pipeline for \"Results: Consequences for object recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "np = numpy\n",
    "plt = pyplot\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import json\n",
    "import os, sys\n",
    "\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "from numpy import *\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import prettyplotlib as ppl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## model-fitting helpers\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def sigmoid(x, x0, k):\n",
    "    y = 1 / (1 + np.exp(-k*(x-x0)))\n",
    "    return y \n",
    "    \n",
    "def sigmoid_alt(x,x0,k,L):\n",
    "    y = L / (1 + np.exp(-k*(x-x0)))\n",
    "    return y\n",
    "\n",
    "def sigmoid_alt4(x,x0,k,L,G):\n",
    "    y = G + ((1 - G - L) / (1 + np.exp(-k*(x-x0))))\n",
    "\n",
    "def piecewise_linear(x, x0, y0, k1, k2):\n",
    "    return np.piecewise(x, [x < x0], [lambda x:k1*x + y0-k1*x0, lambda x:k2*x + y0-k2*x0])\n",
    "\n",
    "def sigmoid_derivative(x, x0, k):\n",
    "    f = np.exp(-k*(x-x0))\n",
    "    return -k / f\n",
    "\n",
    "def fit_sigmoid(x,y):\n",
    "    Ns = len(x)\n",
    "    threshold = []\n",
    "    slope = []\n",
    "    for ss in range(Ns):          \n",
    "        xdata = x[ss]\n",
    "        ydata = y[ss]\n",
    "        skip = 0        \n",
    "        try:\n",
    "            popt, pcov = curve_fit(sigmoid, xdata, ydata,maxfev=300)\n",
    "            if (popt[0]>0) & (popt[0]<1):\n",
    "                threshold.append(popt[0])\n",
    "            else:\n",
    "                threshold.append(nan)\n",
    "            slope.append(popt[1])                           \n",
    "        except:                     \n",
    "            try:\n",
    "                popt, pcov = curve_fit(sigmoid_alt, xdata, ydata,maxfev=800)\n",
    "                if (popt[0]>0) & (popt[0]<1):\n",
    "                    threshold.append(popt[0])\n",
    "                else:\n",
    "                    threshold.append(nan)\n",
    "                slope.append(popt[1])                \n",
    "            except:\n",
    "                plt.figure(figsize(2,2))\n",
    "                skip = 1\n",
    "                plt.plot(xdata,ydata) ## plot the bad fit\n",
    "                plt.title('failed fits')\n",
    "                print 'subject: ' + workers_repd[ss] + ' version: ' + str(versions_repd[ss])\n",
    "                threshold.append(nan)\n",
    "                slope.append(nan)            \n",
    "    return map(np.array,[threshold,slope])\n",
    "\n",
    "def remove_nans(x):\n",
    "    return x[~np.isnan(x)]\n",
    "\n",
    "def compare_phases(pre,post):\n",
    "    diff = post-pre\n",
    "    prop = (post-pre)/pre\n",
    "    return diff,prop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define data directory (where you put downloaded data)\n",
    "data_dir = './data'\n",
    "\n",
    "## load in pre-post data matrix for \n",
    "CPD = pd.read_csv(os.path.join(data_dir,'Categorical_Perception_Recognition_Data_Drawing.csv'))\n",
    "CPO = pd.read_csv(os.path.join(data_dir,'Categorical_Perception_Recognition_Data_Observation.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze pre-post learning from main experiment (Drawing cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### extract key variables from main experiment (drawing cohort)\n",
    "pp = CPD\n",
    "numSubs = len(np.unique(CPD['wID']))\n",
    "p_o1_trained_pre = np.array(pp[(pp['cond']=='trained') & (pp['phase']=='pre')]['p_o1']).reshape(numSubs,6)\n",
    "p_o1_trained_post = np.array(pp[(pp['cond']=='trained') & (pp['phase']=='post')]['p_o1']).reshape(numSubs,6)\n",
    "p_o1_near_pre = np.array(pp[(pp['cond']=='near') & (pp['phase']=='pre')]['p_o1']).reshape(numSubs,6)\n",
    "p_o1_near_post = np.array(pp[(pp['cond']=='near') & (pp['phase']=='post')]['p_o1']).reshape(numSubs,6)\n",
    "baseprop_trained_pre = np.array(pp[(pp['cond']=='trained') & (pp['phase']=='pre')]['baseprop']).reshape(numSubs,6)\n",
    "baseprop_trained_post = np.array(pp[(pp['cond']=='trained') & (pp['phase']=='post')]['baseprop']).reshape(numSubs,6)\n",
    "baseprop_near_pre = np.array(pp[(pp['cond']=='near') & (pp['phase']=='pre')]['baseprop']).reshape(numSubs,6)\n",
    "baseprop_near_post = np.array(pp[(pp['cond']=='near') & (pp['phase']=='post')]['baseprop']).reshape(numSubs,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit logistic function to psychometric data, get slope and threshold parameters\n",
    "threshold_trained_pre,slope_trained_pre = fit_sigmoid(baseprop_trained_pre,p_o1_trained_pre)\n",
    "threshold_trained_post,slope_trained_post = fit_sigmoid(baseprop_trained_post,p_o1_trained_post)\n",
    "threshold_near_pre,slope_near_pre = fit_sigmoid(baseprop_near_pre,p_o1_near_pre)\n",
    "threshold_near_post,slope_near_post = fit_sigmoid(baseprop_near_post,p_o1_near_post)\n",
    "\n",
    "## calculate change in slope\n",
    "diff_trained,prop_trained = compare_phases(slope_trained_pre,slope_trained_post)\n",
    "diff_near,prop_near = compare_phases(slope_near_pre,slope_near_post)\n",
    "\n",
    "slope_trained_diff = slope_trained_post-slope_trained_pre\n",
    "slope_near_diff = slope_near_post-slope_near_pre\n",
    "\n",
    "## calculate change in threshold\n",
    "diff_thresh_trained,prop_thresh_trained = compare_phases(threshold_trained_pre,threshold_trained_post)\n",
    "diff_thresh_near,prop_thresh_near = compare_phases(threshold_near_pre,threshold_near_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_signs(x,rowlabel):\n",
    "    x = remove_nans(x)\n",
    "    print rowlabel + ': <0: ' + str(np.round(sum(x<0)/len(x),4)) + '  =0: ' + str(np.round(sum(x==0)/len(x),4)) + '  >0: ' + str(np.round(sum(x>0)/len(x),4))       \n",
    "\n",
    "print 'Drawing Cohort'\n",
    "print 'PROPORTION OF SUBJECTS WITH SHALLOWER SLOPES (<0), EQUAL SLOPES (=0), OR STEEPER SLOPES (>0)'    \n",
    "tabulate_signs(diff_trained,'trained')\n",
    "tabulate_signs(diff_near,'near')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_boot_CI(data,nIter):\n",
    "    boot_mean = []\n",
    "    for n in range(nIter):\n",
    "        bootgroup = np.random.RandomState(n).choice(data,size=len(data),replace=True) \n",
    "        boot_mean.append(np.nanmean(bootgroup))\n",
    "    boot_mean = map(np.array,[boot_mean]) \n",
    "    return np.mean(boot_mean),np.percentile(boot_mean,2.5), np.percentile(boot_mean,97.5)\n",
    "\n",
    "def get_boot(data,nIter):\n",
    "    boot_mean = []\n",
    "    for n in range(nIter):\n",
    "        bootgroup = np.random.RandomState(n).choice(data,size=len(data),replace=True) \n",
    "        boot_mean.append(np.nanmean(bootgroup))\n",
    "    boot_mean = np.array(boot_mean)\n",
    "    return boot_mean\n",
    "\n",
    "def get_boot_pval(data,nIter):\n",
    "    boot_mean = get_boot(data,nIter)\n",
    "    if np.mean(boot_mean) > 0:\n",
    "        p = (sum(boot_mean<0)/len(boot_mean)) * 2\n",
    "    elif np.mean(boot_mean) < 0:\n",
    "        p = (sum(boot_mean>0)/len(boot_mean)) * 2\n",
    "    else:\n",
    "        p = (sum(boot_mean<0)/len(boot_mean)) * 2\n",
    "    return p\n",
    "\n",
    "def get_boot_SEM(data,nIter):\n",
    "    boot_mean = []\n",
    "    for n in range(nIter):\n",
    "        bootgroup = np.random.RandomState(n).choice(data,size=len(data),replace=True) \n",
    "        boot_mean.append(np.nanmean(bootgroup))\n",
    "    boot_mean = map(np.array,[boot_mean]) \n",
    "    return np.mean(boot_mean),np.percentile(boot_mean,16), np.percentile(boot_mean,84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting quantile-quantile plot against normal distribution \n",
    "def normalize(x):\n",
    "    mu = np.mean(x)\n",
    "    sd = np.std(x)\n",
    "    return (x-mu)/sd\n",
    "\n",
    "sns.set_context('talk')\n",
    "fig = plt.figure(figsize=(9,3))\n",
    "plt.subplot(1,2,1)\n",
    "data = normalize(slope_trained_pre-slope_trained_post)\n",
    "res = stats.probplot(data,plot=plt)\n",
    "plt.subplot(1,2,2)\n",
    "data = normalize(slope_near_pre-slope_near_post)\n",
    "res = stats.probplot(data,plot=plt)\n",
    "\n",
    "## Quantile-quantile plots reveal departure from normal distribution. \n",
    "## Proceeded with nonparametric estimation and inference procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test for difference at pre-test\n",
    "nIter = 10000\n",
    "print 'Drawing Cohort: Slope'\n",
    "print '###### pretest: trained vs. near ######'\n",
    "data = slope_trained_pre-slope_near_pre\n",
    "p = get_boot_pval(data,nIter)\n",
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test for reliability of change in slope (bootstrapped sampling distribution of mean b/c non-normal distribution)\n",
    "nIter = 10000\n",
    "print 'Drawing Cohort: Slope'\n",
    "print '###### trained pre to post ######'\n",
    "data = slope_trained_pre-slope_trained_post\n",
    "p = get_boot_pval(data,nIter)\n",
    "print 'p = ', p\n",
    "print '###### near pre to post ######'\n",
    "data = slope_near_pre-slope_near_post\n",
    "p = get_boot_pval(data,nIter)\n",
    "print 'p = ', p\n",
    "print '###### interaction between trained and near ######'\n",
    "data = diff_trained-diff_near\n",
    "p = get_boot_pval(data,nIter)\n",
    "print 'p = ', p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test for reliability of change in threshold (bootstrapped sampling distribution of mean b/c non-normal distribution)\n",
    "nIter = 10000\n",
    "print 'Drawing Cohort: Threshold'\n",
    "print '###### trained pre to post ######'\n",
    "data = threshold_trained_pre-threshold_trained_post\n",
    "p = get_boot_pval(data,nIter)\n",
    "print 'p = ', p\n",
    "print '###### near pre to post ######'\n",
    "data = threshold_near_pre-threshold_near_post\n",
    "p = get_boot_pval(data,nIter)\n",
    "print 'p = ', p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot change in slope for main experiment (drawing cohort)\n",
    "STDD = slope_trained_diff\n",
    "SNDD = slope_near_diff\n",
    "condition_colors = [(0.7,0.4,0.2),(0.66,0.66,0.66)]\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "m = map(np.nanmean,[STDD, SNDD])\n",
    "mt,lbt,ubt = get_boot_SEM(STDD,5000)\n",
    "mn,lbn,ubn = get_boot_SEM(SNDD,5000)\n",
    "plt.ylim([-30,40])\n",
    "ppl.bar(np.arange(0.1,2.1),m,yerr=np.array([[lbt-mt,ubt-mt],[lbn-mn,ubn-mn]]), \\\n",
    "        ecolor=[0.3,0.3,0.3],color=condition_colors, width=0.8,xticklabels=['Trained','Control'])\n",
    "plt.ylabel('Change in slope (post-pre)')\n",
    "plt.title('Drawing Cohort')\n",
    "plt.savefig('./plots/3_prepost_slope_drawing_cohort.pdf')\n",
    "plt.tight_layout()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Experiment (Dynamic Observation cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### extract key variables from control experiment (Observation cohort)\n",
    "pp = CPO\n",
    "numSubs = len(np.unique(CPD['wID']))\n",
    "p_o1_trained_pre = np.array(pp[(pp['cond']=='trained') & (pp['phase']=='pre')]['p_o1']).reshape(numSubs,6)\n",
    "p_o1_trained_post = np.array(pp[(pp['cond']=='trained') & (pp['phase']=='post')]['p_o1']).reshape(numSubs,6)\n",
    "p_o1_near_pre = np.array(pp[(pp['cond']=='near') & (pp['phase']=='pre')]['p_o1']).reshape(numSubs,6)\n",
    "p_o1_near_post = np.array(pp[(pp['cond']=='near') & (pp['phase']=='post')]['p_o1']).reshape(numSubs,6)\n",
    "baseprop_trained_pre = np.array(pp[(pp['cond']=='trained') & (pp['phase']=='pre')]['baseprop']).reshape(numSubs,6)\n",
    "baseprop_trained_post = np.array(pp[(pp['cond']=='trained') & (pp['phase']=='post')]['baseprop']).reshape(numSubs,6)\n",
    "baseprop_near_pre = np.array(pp[(pp['cond']=='near') & (pp['phase']=='pre')]['baseprop']).reshape(numSubs,6)\n",
    "baseprop_near_post = np.array(pp[(pp['cond']=='near') & (pp['phase']=='post')]['baseprop']).reshape(numSubs,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## fit logistic function to psychometric data, get slope and threshold parameters\n",
    "threshold_trained_pre,slope_trained_pre = fit_sigmoid(baseprop_trained_pre,p_o1_trained_pre)\n",
    "threshold_trained_post,slope_trained_post = fit_sigmoid(baseprop_trained_post,p_o1_trained_post)\n",
    "threshold_near_pre,slope_near_pre = fit_sigmoid(baseprop_near_pre,p_o1_near_pre)\n",
    "threshold_near_post,slope_near_post = fit_sigmoid(baseprop_near_post,p_o1_near_post)\n",
    "\n",
    "## calculate change in slope\n",
    "diff_trained,prop_trained = compare_phases(slope_trained_pre,slope_trained_post)\n",
    "diff_near,prop_near = compare_phases(slope_near_pre,slope_near_post)\n",
    "\n",
    "slope_trained_diff = slope_trained_post-slope_trained_pre\n",
    "slope_near_diff = slope_near_post-slope_near_pre\n",
    "\n",
    "## calculate change in threshold\n",
    "diff_thresh_trained,prop_thresh_trained = compare_phases(threshold_trained_pre,threshold_trained_post)\n",
    "diff_thresh_near,prop_thresh_near = compare_phases(threshold_near_pre,threshold_near_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_signs(x,rowlabel):\n",
    "    x = remove_nans(x)\n",
    "    print rowlabel + ': <0: ' + str(np.round(sum(x<0)/len(x),4)) + '  =0: ' + str(np.round(sum(x==0)/len(x),4)) + '  >0: ' + str(np.round(sum(x>0)/len(x),4))       \n",
    "\n",
    "print 'Observation Cohort'\n",
    "print 'PROPORTION OF SUBJECTS WITH SHALLOWER SLOPES (<0), EQUAL SLOPES (=0), OR STEEPER SLOPES (>0)'    \n",
    "tabulate_signs(diff_trained,'trained')\n",
    "tabulate_signs(diff_near,'near')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting quantile-quantile plot against normal distribution \n",
    "def normalize(x):\n",
    "    mu = np.mean(x)\n",
    "    sd = np.std(x)\n",
    "    return (x-mu)/sd\n",
    "\n",
    "sns.set_context('talk')\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "data = normalize(slope_trained_pre-slope_trained_post)\n",
    "res = stats.probplot(data,plot=plt)\n",
    "plt.subplot(1,2,2)\n",
    "data = normalize(slope_near_pre-slope_near_post)\n",
    "res = stats.probplot(data,plot=plt)\n",
    "\n",
    "## Quantile-quantile plots reveal departure from normal distribution. \n",
    "## Proceeded with nonparametric estimation and inference procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test for reliability of change in slope (bootstrapped sampling distribution of mean b/c non-normal distribution)\n",
    "nIter = 10000\n",
    "print 'Drawing Cohort'\n",
    "print '###### trained pre to post ######'\n",
    "data = slope_trained_pre-slope_trained_post\n",
    "p = get_boot_pval(data,nIter)\n",
    "print 'p = ', p\n",
    "print '###### near pre to post ######'\n",
    "data = slope_near_pre-slope_near_post\n",
    "p = get_boot_pval(data,nIter)\n",
    "print 'p = ', p\n",
    "print '###### interaction between trained and near ######'\n",
    "data = diff_trained-diff_near\n",
    "p = get_boot_pval(data,nIter)\n",
    "print 'p = ', p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot change in slope for control experiment (Observation cohort)\n",
    "STDO = slope_trained_diff\n",
    "SNDO = slope_near_diff\n",
    "condition_colors = [(0.7,0.4,0.2),(0.66,0.66,0.66)]\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "m = map(np.nanmean,[STDO, SNDO])\n",
    "mt,lbt,ubt = get_boot_SEM(STDO,5000)\n",
    "mn,lbn,ubn = get_boot_SEM(SNDO,5000)\n",
    "plt.ylim([-30,40])\n",
    "ppl.bar(np.arange(0.1,2.1),m,yerr=np.array([[lbt-mt,ubt-mt],[lbn-mn,ubn-mn]]), \\\n",
    "        ecolor=[0.3,0.3,0.3],color=condition_colors, width=0.8,xticklabels=['Trained','Control'])\n",
    "plt.ylabel('Change in slope (post-pre)')\n",
    "plt.title('Observation Cohort')\n",
    "plt.savefig('./plots/3_prepost_slope_observation_cohort.pdf')\n",
    "plt.tight_layout()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test for interaction between group (Drawing vs. Observation) and condition (Trained vs. Control)\n",
    "nIter = 10000\n",
    "print 'Interaction between group (Drawing vs. Observation) and condition (Trained vs. Control)'\n",
    "data = (STDD-SNDD)-(STDO-SNDO)\n",
    "p = get_boot_pval(data,nIter)\n",
    "print 'p = ', p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test for reliability of change in threshold (bootstrapped sampling distribution of mean b/c non-normal distribution)\n",
    "nIter = 10000\n",
    "print 'Observation Cohort: Threshold'\n",
    "print '###### trained pre to post ######'\n",
    "data = threshold_trained_pre-threshold_trained_post\n",
    "p = get_boot_pval(data,nIter)\n",
    "print 'p = ', p\n",
    "print '###### near pre to post ######'\n",
    "data = threshold_near_pre-threshold_near_post\n",
    "p = get_boot_pval(data,nIter)\n",
    "print 'p = ', p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
