{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### jefan \n",
    "#### begun: Dec 29 2016, updated: Jul 15 2018\n",
    "#### analysis pipeline for \"Results: Generalized object representations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import prettyplotlib as ppl\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "from pylab import *\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "cm = matplotlib.cm\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define data directory (where you put downloaded data)\n",
    "data_dir = './data'\n",
    "\n",
    "## modify python path in order to load in useful variables\n",
    "CURR_DIR = os.getcwd()\n",
    "\n",
    "if os.path.join(CURR_DIR) not in sys.path:\n",
    "    sys.path.append(CURR_DIR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import list of 105 corresponding categories (between Imagenet and Eitz datasets)\n",
    "from inet_sketch_cats import CATS\n",
    "Cats = CATS\n",
    "\n",
    "## standardized ordering of categories for ease of visualization\n",
    "from inet_sketch_cats import STANDARD_ORDER\n",
    "standard_order = STANDARD_ORDER\n",
    "\n",
    "## standardized ordering of categories for ease of visualization\n",
    "from inet_sketch_cats import SKLOOP_OBJS\n",
    "skloop_objs = SKLOOP_OBJS\n",
    "\n",
    "## load dictionary with correpsondences between Imagenet and Eitz labels\n",
    "from inet_sketch_cats import INET_TO_SKETCH\n",
    "inet_to_sketch = INET_TO_SKETCH\n",
    "\n",
    "## load in dictionary with cluster assignments\n",
    "from inet_sketch_cats import CLUSTER_OBJ_LIST\n",
    "clusterObjList = CLUSTER_OBJ_LIST\n",
    "clusterObjList = reduce(lambda x, y: list(x) + list(y), clusterObjList.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## fix incongruities between original eitz and preferred spellings\n",
    "meta_eitz = pd.read_csv(os.path.join(data_dir,'meta_eitz.csv'))\n",
    "correspondence = dict([(x, x) for x in np.unique(meta_eitz['category'])])\n",
    "correspondence['crane'] = 'crane (machine)'\n",
    "correspondence['loudspeakers'] = 'loudspeaker'\n",
    "correspondence['loudspeaker'] = 'loudspeakers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in mean feature vectors for each class and generate RDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imF_means_layer1 = np.load(os.path.join(data_dir,'inet_class_means_layer1.npy'))\n",
    "imF_means_fc6 = np.load(os.path.join(data_dir,'inet_class_means_fc6.npy'))\n",
    "\n",
    "skF_means_layer1 = np.load(os.path.join(data_dir,'eitz_class_means_layer1.npy'))\n",
    "skF_means_fc6 = np.load(os.path.join(data_dir,'eitz_class_means_fc6.npy'))\n",
    "\n",
    "# load in other layers\n",
    "skF_means_layer2 = np.load(os.path.join(data_dir,'eitz_class_means_layer2.npy'))\n",
    "skF_means_layer3 = np.load(os.path.join(data_dir,'eitz_class_means_layer3.npy'))\n",
    "skF_means_layer4 = np.load(os.path.join(data_dir,'eitz_class_means_layer4.npy'))\n",
    "skF_means_layer5 = np.load(os.path.join(data_dir,'eitz_class_means_layer5.npy'))\n",
    "\n",
    "imF_means_layer2 = np.load(os.path.join(data_dir,'inet_class_means_layer2.npy'))\n",
    "imF_means_layer3 = np.load(os.path.join(data_dir,'inet_class_means_layer3.npy'))\n",
    "imF_means_layer4 = np.load(os.path.join(data_dir,'inet_class_means_layer4.npy'))\n",
    "imF_means_layer5 = np.load(os.path.join(data_dir,'inet_class_means_layer5.npy'))\n",
    "\n",
    "assert imF_means_fc6.shape[0] == 105\n",
    "assert skF_means_fc6.shape[0] == 105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rdm(X,size):\n",
    "    sns.set_style('white')\n",
    "    sns.set_context('paper')\n",
    "    fig = plt.figure(figsize=(size,size))\n",
    "    fig.gca().matshow(X,cmap=cm.inferno)\n",
    "    plt.xticks(range(len(standard_order)), standard_order, rotation=90);\n",
    "    plt.yticks(range(len(standard_order)), standard_order); \n",
    "\n",
    "    for tick in pylab.gca().xaxis.iter_ticks():\n",
    "        tick[0].label2On = True\n",
    "        tick[0].label1On = False\n",
    "        tick[0].label2.set_rotation('vertical')\n",
    "        tick[0].tick1On = False\n",
    "        tick[0].tick2On = False\n",
    "    for tick in pylab.gca().yaxis.iter_ticks():\n",
    "        tick[0].tick1On = False\n",
    "        tick[0].tick2On = False\n",
    "        \n",
    "def plot_rdms_adjacent(X1,X2):\n",
    "    '''\n",
    "    X1 = feature means within each class for bottom layer\n",
    "    X2 = feature means within each class for top layer    \n",
    "    '''\n",
    "    import seaborn as sns\n",
    "    import matplotlib.cm as cm\n",
    "    sns.set_style('white')\n",
    "    sns.set_context('paper')\n",
    "    fig = plt.figure(figsize=(24,12))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    ax = fig.gca().matshow(X1,cmap=cm.inferno)\n",
    "    plt.xticks(range(len(standard_order)), standard_order, rotation=90);\n",
    "    plt.yticks(range(len(standard_order)), standard_order); \n",
    "    plt.colorbar(ax)\n",
    "\n",
    "    for tick in pylab.gca().xaxis.iter_ticks():\n",
    "        tick[0].label2On = True\n",
    "        tick[0].label1On = False\n",
    "        tick[0].label2.set_rotation('vertical')\n",
    "        tick[0].tick1On = False\n",
    "        tick[0].tick2On = False\n",
    "    for tick in pylab.gca().yaxis.iter_ticks():\n",
    "        tick[0].tick1On = False\n",
    "        tick[0].tick2On = False    \n",
    "        \n",
    "    plt.subplot(1,2,2)       \n",
    "    fig.gca().matshow(X2,cmap=cm.inferno)\n",
    "    plt.xticks(range(len(standard_order)), standard_order, rotation=90);\n",
    "    plt.yticks(range(len(standard_order)), standard_order); \n",
    "\n",
    "    for tick in pylab.gca().xaxis.iter_ticks():\n",
    "        tick[0].label2On = True\n",
    "        tick[0].label1On = False\n",
    "        tick[0].label2.set_rotation('vertical')\n",
    "        tick[0].tick1On = False\n",
    "        tick[0].tick2On = False\n",
    "    for tick in pylab.gca().yaxis.iter_ticks():\n",
    "        tick[0].tick1On = False\n",
    "        tick[0].tick2On = False     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Plot RDMs based on bottom ('layer1') and top ('fc6') layer feature representations for sketch domain (Eitz corpus)\n",
    "sketch_rdm_layer1 = 1 - np.corrcoef(skF_means_layer1)\n",
    "sketch_rdm_fc6 = 1 - np.corrcoef(skF_means_fc6)\n",
    "plot_rdms_adjacent(sketch_rdm_layer1,sketch_rdm_fc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot RDMs based on bottom ('layer1') and top ('fc6') layer feature representations for photo domain (Imagenet)\n",
    "photo_rdm_layer1 = 1 - np.corrcoef(imF_means_layer1)\n",
    "photo_rdm_fc6 = 1 - np.corrcoef(imF_means_fc6)\n",
    "plot_rdms_adjacent(photo_rdm_layer1,photo_rdm_fc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute cross-domain RDM similarity (\"second-order similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## compute cross-domain similarity\n",
    "def get_rdm_similarity(a,b):\n",
    "    '''\n",
    "    \"a\" is one RDM made from, e.g., sketches\n",
    "    \"b\" is another RDM made from, e.g., photos\n",
    "    what is between-RDM similarity?\n",
    "    '''    \n",
    "    import scipy.spatial.distance as dist\n",
    "    xdist = stats.pearsonr(dist.squareform(a, checks=False), dist.squareform(b, checks=False))    \n",
    "    return xdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set up pipeline to generate RDMs for all intermediate layers as well\n",
    "\n",
    "def load_and_get_rdm(domain,layer,data_dir):\n",
    "    if domain in ['photo','imagenet','inet']:\n",
    "        d = 'inet'\n",
    "    elif domain in ['sketch','eitz']:\n",
    "        d = 'eitz'\n",
    "    else:\n",
    "        print 'Not valid domain!'\n",
    "    means = np.load(os.path.join(data_dir,'{}_class_means_{}.npy'.format(d,layer)))\n",
    "    rdm = 1 - np.corrcoef(means)\n",
    "    return rdm\n",
    "    \n",
    "    \n",
    "photo_rdm_layer2 = load_and_get_rdm('photo','layer2',data_dir)\n",
    "photo_rdm_layer3 = load_and_get_rdm('photo','layer3',data_dir)\n",
    "photo_rdm_layer4 = load_and_get_rdm('photo','layer4',data_dir)    \n",
    "photo_rdm_layer5 = load_and_get_rdm('photo','layer5',data_dir)    \n",
    "\n",
    "sketch_rdm_layer2 = load_and_get_rdm('eitz','layer2',data_dir)\n",
    "sketch_rdm_layer3 = load_and_get_rdm('eitz','layer3',data_dir)\n",
    "sketch_rdm_layer4 = load_and_get_rdm('eitz','layer4',data_dir)    \n",
    "sketch_rdm_layer5 = load_and_get_rdm('eitz','layer5',data_dir) \n",
    "\n",
    "sketch_rdms = np.dstack((sketch_rdm_layer1,sketch_rdm_layer2,sketch_rdm_layer3,sketch_rdm_layer4,sketch_rdm_layer5,sketch_rdm_fc6))\n",
    "photo_rdms = np.dstack((photo_rdm_layer1,photo_rdm_layer2,photo_rdm_layer3,photo_rdm_layer4,photo_rdm_layer5,photo_rdm_fc6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "dister = []\n",
    "for l in range(sketch_rdms.shape[2]):\n",
    "    r,p = get_rdm_similarity(sketch_rdms[:,:,l],photo_rdms[:,:,l])\n",
    "    dister.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dister = np.array(dister)    \n",
    "print 'cross-domain similarity by layer'\n",
    "print np.round(dister,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "h = plt.plot(np.arange(len(dister))+1,dister, color=[0.2, 0.2, 0.2])\n",
    "plt.xticks(np.arange(1,len(dister)+1))\n",
    "h[0].set_color([0.2, 0.2, 0.2])\n",
    "plt.xlabel('model layer')\n",
    "plt.ylabel('photo-sketch similarity (r)')\n",
    "plt.xlim([0.8,6.2])\n",
    "plt.ylim([0,0.6])\n",
    "if not os.path.exists('./plots'):\n",
    "    os.makedirs('./plots')\n",
    "plt.tight_layout()        \n",
    "plt.savefig('./plots/1_crossdomain_similarity_by_layer.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### First order comparison between feature representations across sketch and photo domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get direct measure of correspondence between sketch & photo feature vectors \n",
    "# (1) stack photo and sketch matrices; (2) Off-diagonal 105x105 super-block contains diagonal vector (105)\n",
    "# with \"direct\" correlation between class means computed separately for each domain\n",
    "stacked_fc6 = np.vstack((imF_means_fc6,skF_means_fc6))\n",
    "stacked_mat = np.corrcoef(stacked_fc6)\n",
    "## uncomment next line if you want to plot rdm for stacked fc6 feature mat\n",
    "# plot_rdm(stacked_mat,24)\n",
    "# get off-diagonal superblock\n",
    "off_diag = stacked_mat[105:,:105]\n",
    "# get diagonal of this superblock\n",
    "corr_fc6 = np.diagonal(off_diag)\n",
    "# get off-diagonal elements of this superblock\n",
    "inds = np.triu_indices(np.shape(off_diag)[0],1)\n",
    "off_diag_fc6 = off_diag[inds[0],inds[1]]\n",
    "print 'fc6 features: sketch-photo correspondence | same_obj r = {}, diff_obj r = {}'.format(np.round(np.mean(corr_fc6),3),np.round(np.mean(off_diag_fc6),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do same for layer1 features\n",
    "stacked_layer1 = np.vstack((imF_means_layer1,skF_means_layer1))\n",
    "stacked_mat = np.corrcoef(stacked_layer1)\n",
    "## uncomment next line if you want to plot stacked_mat for layer1\n",
    "# plot_rdm(stacked_mat,24)\n",
    "# get off-diagonal superblock\n",
    "off_diag = stacked_mat[105:,:105]\n",
    "# get diagonal of this superblock\n",
    "corr_layer1 = np.diagonal(off_diag)\n",
    "# get off-diagonal elements of this superblock\n",
    "inds = np.triu_indices(np.shape(off_diag)[0],1)\n",
    "off_diag_layer1 = off_diag[inds[0],inds[1]]\n",
    "print 'layer1 features: sketch-photo correspondence | same_obj r = {}, diff_obj r = {}'.format(np.round(np.mean(corr_layer1),3),np.round(np.mean(off_diag_layer1),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correspondence_within_class_between_domains(im_means,sk_means):\n",
    "    stacked = np.vstack((im_means,sk_means))\n",
    "    stacked_mat = np.corrcoef(stacked)\n",
    "    # get off-diagonal superblock\n",
    "    off_diag = stacked_mat[105:,:105]\n",
    "    # get diagonal of this superblock\n",
    "    diag = np.diagonal(off_diag)\n",
    "    # get off-diagonal elements of this superblock\n",
    "    inds = np.triu_indices(np.shape(off_diag)[0],1)\n",
    "    off_diag = off_diag[inds[0],inds[1]]\n",
    "    return diag, off_diag\n",
    "\n",
    "def get_boot_diff(x1,x2,nIter):\n",
    "    boot_mean = []\n",
    "    for i in range(nIter):\n",
    "        boot1 = np.random.RandomState(i).choice(range(x1.shape[0]),size=x1.shape[0],replace=True)\n",
    "        boot2 = np.random.RandomState(i).choice(range(x2.shape[0]),size=x2.shape[0],replace=True)\n",
    "        boot_mean.append(np.mean(x1[boot1])-np.mean(x2[boot2]))\n",
    "    p = sum(boot_mean<0)/nIter * 2\n",
    "    return np.array(boot_mean), p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute diag vs. off-diag for all layers\n",
    "x1 = imF_means_layer1\n",
    "x2 = skF_means_layer1\n",
    "diag_layer1, off_diag_layer1 = correspondence_within_class_between_domains(x1,x2)\n",
    "x1 = imF_means_layer2\n",
    "x2 = skF_means_layer2\n",
    "diag_layer2, off_diag_layer2 = correspondence_within_class_between_domains(x1,x2)\n",
    "x1 = imF_means_layer3\n",
    "x2 = skF_means_layer3\n",
    "diag_layer3, off_diag_layer3 = correspondence_within_class_between_domains(x1,x2)\n",
    "x1 = imF_means_layer4\n",
    "x2 = skF_means_layer4\n",
    "diag_layer4, off_diag_layer4 = correspondence_within_class_between_domains(x1,x2)\n",
    "x1 = imF_means_layer5\n",
    "x2 = skF_means_layer5\n",
    "diag_layer5, off_diag_layer5 = correspondence_within_class_between_domains(x1,x2)\n",
    "x1 = imF_means_fc6\n",
    "x2 = skF_means_fc6\n",
    "diag_fc6, off_diag_fc6 = correspondence_within_class_between_domains(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also plot first order similarity (correlations between sketch and photo of same object)\n",
    "import seaborn as sns\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "diag = map(np.mean,[diag_layer1, diag_layer2, diag_layer3, diag_layer4, diag_layer5, diag_fc6])\n",
    "h = plt.plot(np.arange(6)+1,diag, color=[0.2, 0.2, 0.2])\n",
    "plt.xticks(np.arange(1,len(dister)+1))\n",
    "h[0].set_color([0.2, 0.2, 0.2])\n",
    "plt.xlabel('model layer')\n",
    "plt.ylabel('photo-sketch first-order similarity (r)')\n",
    "xx = plt.xlim([0.8,6.2])\n",
    "yy = plt.ylim([0,0.3])\n",
    "plt.close(fig)\n",
    "if not os.path.exists('./plots'):\n",
    "    os.makedirs('./plots')\n",
    "plt.tight_layout()    \n",
    "plt.savefig('./plots/1_crossdomain_first_order_similarity_by_layer.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import dldata.metrics.utils as utils # compute_metric method deprecated, moving onto sci-kit learn methods\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load raw features and subset by 105 categories of interest shared across photo and sketch domains\n",
    "meta = pd.read_csv(os.path.join(data_dir,'meta_eitz_250.csv'))  ## full 250 category list from Eitz paper\n",
    "cats250 = meta['category']\n",
    "inds = [i for i, j in enumerate(cats250) if j in CATS] # indices of original sketch set that are actually part of the correspondence\n",
    "skF_feats_fc6 = np.load(os.path.join(data_dir,'eitz_features_fc6.npy')) ## loading in full fc6 feature matrix for Eitz dataset\n",
    "feats = skF_feats_fc6[inds,:]\n",
    "cats = cats250[inds]\n",
    "assert (len(feats)==8320) & (len(cats)==len(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cross validation split and get score for single cross-validation split\n",
    "from sklearn import model_selection\n",
    "from sklearn import svm\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    feats, cats, test_size=0.2, random_state=0)\n",
    "\n",
    "# accuracy using SVM classifier with linear kernel\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "print clf.score(X_test, y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5-fold crossval classification accuracy\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "## Running this will take a few minutes, so set the reallyRun flag to True if you really want to run.\n",
    "reallyRun = False\n",
    "if reallyRun:\n",
    "    clf = svm.SVC(kernel='linear', C=1)\n",
    "    scores = model_selection.cross_val_score(\n",
    "       clf, feats, cats, cv=5)\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print \"Time taken: \", elapsed, \"seconds.\"  \n",
    "\n",
    "    ## 'fc6' layer representation\n",
    "    print scores\n",
    "    print np.mean(scores), '% mean accuracy on 5 splits'\n",
    "    print np.std(scores)\n",
    "    \n",
    "    ## plot recognition accuracy\n",
    "    scores_fc6 = scores\n",
    "    sns.set_style('white')\n",
    "    sns.set_context('poster')\n",
    "    textsize = 16\n",
    "    fig = plt.figure(figsize=(1,6))\n",
    "    ind = 0\n",
    "    width = 0.8\n",
    "    y = np.mean(scores_fc6)\n",
    "    lb = np.percentile(scores_fc6,2.5)\n",
    "    ub = np.percentile(scores_fc6,97.5)\n",
    "    rect = ppl.bar(np.arange(1),[y],width,color=ppl.colors.set1,ecolor='k',xticklabels=['top'])\n",
    "    rect = plt.errorbar(width/2,[y],yerr=[np.array(y-lb,ub-y)],ecolor='k')\n",
    "    plt.ylabel('model recognition accuracy (cross-validated)',fontsize=textsize)\n",
    "    plt.ylim([0,1.0])\n",
    "    plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "    plt.tick_params(axis='both', which='minor', labelsize=18)    \n",
    "    plt.tight_layout() \n",
    "    plt.savefig('./plots/1_fc6_sketch_classification_accuracy.pdf')\n",
    "    plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
